# bubi_prediction

The 'bubi_prediction' project was generated by using the default-python template.

## TODO

To make predictions with the prophet model, we must use the make_future_dataframe of the trained Prophet model. For this, we need to load it with mlflow.prophet.load_model. To retain the possibility for replacement with another type of model later, it would be nice to load it as a pyfunc, but then there is no make_future_dataframe. The solution is to wrap the model in a PythonModel. Then we can also post process it to return a non-negative integer.

We cannot load it as a Spark UDF as far as I know. So then we should make the predictions as a Pandas dataframe, create a Spark DF out of it, then merge it into a table that contains the predictions so far. We should also store the model version and the date of prediction in that so far, so it could be SCD type 2.

"module prophet not found" -- the issue was that mlflow versions were mismatched and prophet was missing in the notebook.

## Resources

Databricks notebook on model training with feature engineering client:

<https://docs.databricks.com/en/_extras/notebooks/source/machine-learning/feature-store-with-uc-taxi-example.html>

How to provide libraries for a .py file on serverless compute:

```[yaml]
resources:
  jobs:
    Serverless_dependency_test:
      name: Serverless dependency test
      tasks:
        - task_key: prophet
          spark_python_task:
            python_file: /Workspace/Users/toth.bence.mihaly@gmail.com/prophet.py
          min_retry_interval_millis: 900000
          disable_auto_optimization: true
          environment_key: bubi_environment
      queue:
        enabled: true
      environments:
        - environment_key: bubi_environment
          spec:
            environment_version: "2"
            dependencies:
              - -r /Workspace/Users/toth.bence.mihaly@gmail.com/requirements.txt
      performance_target: PERFORMANCE_OPTIMIZED
```
